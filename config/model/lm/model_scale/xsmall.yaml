# @package _global_
# just used for debugging or when we just want to populate the cache
# and do not care about training.

transformer_lm:
  dim: 64
  num_heads: 2
  num_layers: 2

transfer_lm:
  transfer_dim: 64
  transfer_num_heads: 4
  transfer_num_layers: 1